{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords():\n",
    "    # File path to the outline document\n",
    "    file_path = 'out/QA.outline'\n",
    "\n",
    "    # Read the entire file content\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    # Use regular expression to find all instances of chapter names in <a> tags\n",
    "    chapter_details = re.findall(\n",
    "    r'<a class=\"l\"[^>]*data-dest-detail=\\'\\[(\\d+),[^\\]]+\\]\\'>(.*?)\\s*</a>',\n",
    "    file_content\n",
    "    )\n",
    "\n",
    "    chapter_to_number_dict = {detail[1].strip(): int(detail[0]) for detail in chapter_details}\n",
    "    chapter_names = [k.replace(\"&amp;\", \"&\").strip() for k, v in chapter_to_number_dict.items()]\n",
    "    return chapter_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"pdf2htmlEX --embed cfijo --dest-dir out data/QA.pdf\")\n",
    "# html2text out/QA.html utf-8 --ignore-links --escape-all > 1.txt\n",
    "\n",
    "with open(\"1.txt\", 'r', encoding='UTF-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "sections = re.split(r'!\\[\\]\\(.+?\\)', text)\n",
    "# 去掉页眉和页妈\n",
    "for i in range(len(sections)):\n",
    "    sections[i] = re.sub(rf'^.*?\\n{i}\\n', \"\", sections[i], flags=re.DOTALL)\n",
    "\n",
    "all_text = \"\".join(sections).replace(\"\\n\\n\", \"\\n\")\n",
    "with open(\"all.txt\", 'w', encoding='UTF-8') as f:\n",
    "    f.write(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = ['，', '。', '：', '！', '-', '的', '是']\n",
    "\n",
    "end_delimiter = ['。', '！', '？', '!', '?', '-', '的', '是']\n",
    "\n",
    "keywords = get_keywords()\n",
    "MAX_KEYWORD_LEN = 20\n",
    "MAX_SENTENCE_LEN = 30\n",
    "\n",
    "sections = defaultdict(str)\n",
    "chapter_name = \"\"\n",
    "tmp = \"\"\n",
    "with open(\"all.txt\", 'r', encoding='UTF-8') as f:\n",
    "    for line in f.readlines():\n",
    "        if line.strip() in keywords:\n",
    "            if chapter_name != \"\":\n",
    "                sections[chapter_name] += \"<SEP>\" + tmp\n",
    "                tmp = \"\"\n",
    "            chapter_name = line.strip()\n",
    "        else:\n",
    "            tmp += line\n",
    "sections[chapter_name] = tmp\n",
    "\n",
    "subsection_dict = defaultdict(list)\n",
    "\n",
    "for chapter_name, text in sections.items():\n",
    "    # 切分句子\n",
    "    sentences = text.split('\\n')\n",
    "    # 处理每个句子\n",
    "    processed_sentences = \"\"\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) == 0:\n",
    "            continue\n",
    "        # 可能包含章节数字 1.1 标题\n",
    "        elif re.match(r\"^\\d+(\\.\\d+){0,1,2}\\s+.*$\", sentence) and any(not sentence.endswith(it) for it in end_delimiter):\n",
    "            processed_sentences += \"\\n\" + sentence + \"\\n\"\n",
    "        # 句子长度小于最大关键词长度，且不包含分隔符\n",
    "        elif len(sentence) < MAX_KEYWORD_LEN and not any(it in sentence for it in delimiter):\n",
    "            processed_sentences += \"\\n\" + sentence + \"\\n\"\n",
    "        # 拼接上下句子\n",
    "        elif len(sentence) > MAX_SENTENCE_LEN - 2 or (\"，\" in sentence and not sentence.endswith(\"。\")):\n",
    "            processed_sentences += sentence\n",
    "        # 换行后第一个字符是分隔符\n",
    "        elif any(sentence.startswith(it) for it in delimiter):\n",
    "            processed_sentences = processed_sentences[:-1] + sentence + \"\\n\"\n",
    "        else:\n",
    "            processed_sentences += sentence + \"\\n\"\n",
    "\n",
    "    # 重新组合文本\n",
    "    processed_sentences = processed_sentences.strip(\"\\n\")\n",
    "    if len(processed_sentences) > 0:\n",
    "        sections[chapter_name] = processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_docs_to_jsonl(array, file_path:str)->None:\n",
    "    with open(file_path, 'w') as jsonl_file:\n",
    "        for doc in array:\n",
    "            jsonl_file.write(json.dumps(doc.dict(), ensure_ascii=False) + '\\n')\n",
    "\n",
    "\n",
    "# print(sections[\"前向碰撞减缓系统\"])\n",
    "chunk_size = 200\n",
    "chunk_overlap = 20\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    add_start_index=True,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "\n",
    "\n",
    "section_docs = text_splitter.create_documents(list(sections.values()), metadatas=[{\"keyword\": k} for k in sections.keys()])\n",
    "save_docs_to_jsonl(section_docs, \"section_docs.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS \n",
    "\n",
    "model_name = \"/home/lzw/.hf_models/stella-base-zh-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\"device\": \"cuda\"} ,\n",
    "    encode_kwargs={\"normalize_embeddings\": False})\n",
    "db = FAISS.from_documents(section_docs, embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={'k': 5})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "query = \"设置无钥匙解锁中单门和全车的区别在于什么？?\"\n",
    "ret_docs = retriever.get_relevant_documents(query)\n",
    "all_sent = [doc.page_content for doc in ret_docs]\n",
    "all_sent\n",
    "# sent_db.similarity_search(query, top_k=)\n",
    "# print(ret_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100\n",
    "chunk_overlap = 10\n",
    "sentence_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "\n",
    "sent_docs = sentence_splitter.split_documents(section_docs)\n",
    "save_docs_to_jsonl(sent_docs, \"sent_docs.jsonl\")\n",
    "sent_db = FAISS.from_documents(sent_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"驾驶员状态监测系统是如何工作的？\"\n",
    "sent_retriever = sent_db.as_retriever(search_kwargs={'k': 5})\n",
    "sent_retriever.get_relevant_documents(query)\n",
    "index_retriever.get_relevant_documents(query)\n",
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "query = \"如何启用或停用手套箱密码保护功能？\"\n",
    "bm25_retriever = BM25Retriever.from_texts(list(sections.keys()))\n",
    "bm25_retriever.get_relevant_documents(query)\n",
    "index_retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parent vectorstore\n",
    "`https://python.langchain.com/docs/modules/data_connection/retrievers/parent_document_retriever`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/lzw/.hf_models/stella-base-zh-v2. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "model_name = \"/home/lzw/.hf_models/stella-base-zh-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\"device\": \"cuda\"} ,\n",
    "    encode_kwargs={\"normalize_embeddings\": False})\n",
    "# This text splitter is used to create the child documents\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\", \"。\\n\"],\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0,\n",
    "    )\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_documents\", embedding_function=embeddings\n",
    ")\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "import json\n",
    "def load_docs_from_jsonl(file_path):\n",
    "    array = []\n",
    "    with open(file_path, 'r') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            data = json.loads(line)\n",
    "            obj = Document(**data)\n",
    "            array.append(obj)\n",
    "    return array\n",
    "\n",
    "section_docs = load_docs_from_jsonl(\"section_docs.jsonl\")\n",
    "retriever.add_documents(section_docs, ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='■ 冬季使用雨刮前，请先清除挡风玻璃上的冰和积雪并确认雨刮片没有冻结在挡风玻璃上。\\n■ 当挡风玻璃上有尘沙、鸟粪、昆虫、树浆等异物时，请先清洁挡风玻璃，否则会损坏雨刮片/影响雨刮片清洁效果。', metadata={'doc_id': 'b8c510bb-9ffd-450b-b0f4-941f62fd40a6', 'keyword': '后雨刮和洗涤器', 'start_index': 0}),\n",
       " Document(page_content='■ 恶劣天气下能见度降低：强降雪、高吹雪、雨、浓雾和多尘天气对挡风玻璃和前保险杠均有影响，可能会降低系统功能。', metadata={'doc_id': 'd68a3a12-bf2c-465b-85c4-552c8d6bb5f5', 'keyword': '前向碰撞减缓系统（CMSF）局限性', 'start_index': 1117}),\n",
       " Document(page_content='<SEP>冬季行驶\\n冬季行驶前，有必要做好准备工作和检查工作。冬季来临前，请检查以下几项：\\n■ 在发动机冷却液壶中加入足量防冻液。为获取最佳防冻效果，请使用正确规格的冷却液。', metadata={'doc_id': 'acce8e5d-3ec9-4c8f-9373-5353e7233b52', 'keyword': '冬季行驶', 'start_index': 0}),\n",
       " Document(page_content='■ 避免在挡风玻璃干燥的情况下开启雨刮，否则可能导致雨刮片和挡风玻璃损坏。■ 定期清洁和检查雨刮片，否则雨刮片使用寿命可能会缩短。', metadata={'doc_id': 'b8c510bb-9ffd-450b-b0f4-941f62fd40a6', 'keyword': '后雨刮和洗涤器', 'start_index': 0})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = vectorstore.similarity_search(\"为什么驾驶之前需要确保挡风玻璃无冰渣、积雪或冷凝水？\")\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This text splitter is used to create the parent documents\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "# This text splitter is used to create the child documents\n",
    "# It should create documents smaller than the parent\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=20, chunk_overlap=0)\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"split_parents\", embedding_function=embeddings\n",
    ")\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")\n",
    "retriever.add_documents(section_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(store.yield_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Document(page_content='<SEP>紧急情况下，您可以使用机械方式从车内应急打开尾门。1 折叠后排座椅靠背，进入后备厢。\\n2 使用机械钥匙或类似工具，拆下保护盖。\\n3 沿箭头方向拨动控制杆，解锁尾门。\\n4 向外推动，打开尾门。', metadata={'doc_id': '03028a02-8d7f-478b-ae37-9cabdfbb861b', 'keyword': '应急打开尾门', 'start_index': 0}),\n",
       "  Document(page_content='<SEP>紧急情况下，您可以使用机械方式从车内应急打开尾门。1 折叠后排座椅靠背，进入后备厢。\\n2 使用机械钥匙或类似工具，拆下保护盖。\\n3 沿箭头方向拨动控制杆，解锁尾门。\\n4 向外推动，打开尾门。', metadata={'doc_id': '97dac7f1-b7bd-4869-9127-03d0e4b25ae6', 'keyword': '应急打开尾门', 'start_index': 0}),\n",
       "  Document(page_content='<SEP>打开尾门\\n\\n尾门开启按键\\n车辆处于解锁状态时，轻按尾门下部的开启按键，尾门自动打开。说明！□ 打开/关闭尾门，后备厢灯会相应地自动点亮或熄灭。\\n□ 尾门打开时，车辆将自动点亮后部位置灯，以提醒后方车辆的驾驶员，避免发生碰撞。\\n\\n关闭尾门', metadata={'doc_id': 'd4e26474-248a-4785-b685-855e0774e8c9', 'keyword': '打开尾门', 'start_index': 0}),\n",
       "  Document(page_content='<SEP>打开尾门\\n\\n尾门开启按键\\n车辆处于解锁状态时，轻按尾门下部的开启按键，尾门自动打开。说明！□ 打开/关闭尾门，后备厢灯会相应地自动点亮或熄灭。', metadata={'doc_id': '640a2964-ba9b-4889-9897-04adab2c898b', 'keyword': '打开尾门', 'start_index': 0})],\n",
       " [Document(page_content='<SEP>紧急情况下，您可以使用机械方式从车内应急打开尾门。1 折叠后排座椅靠背，进入后备厢。\\n2 使用机械钥匙或类似工具，拆下保护盖。\\n3 沿箭头方向拨动控制杆，解锁尾门。\\n4 向外推动，打开尾门。', metadata={'keyword': '应急打开尾门', 'start_index': 0}),\n",
       "  Document(page_content='<SEP>打开尾门\\n\\n尾门开启按键\\n车辆处于解锁状态时，轻按尾门下部的开启按键，尾门自动打开。说明！□ 打开/关闭尾门，后备厢灯会相应地自动点亮或熄灭。\\n□ 尾门打开时，车辆将自动点亮后部位置灯，以提醒后方车辆的驾驶员，避免发生碰撞。\\n\\n关闭尾门', metadata={'keyword': '打开尾门', 'start_index': 0})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_docs = vectorstore.similarity_search(\"如何打开车辆尾门？\")\n",
    "ret_docs = retriever.get_relevant_documents(\"如何打开车辆尾门？\")\n",
    "sub_docs, ret_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
