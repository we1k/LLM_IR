{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from typing import Dict, Tuple, Iterable\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.llms import ChatGLM\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from src.llm.template_manager import template_manager\n",
    "from src.parse_pdf import parse_page_of_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs_from_jsonl(file_path)->Iterable[Document]:\n",
    "    array = []\n",
    "    with open(file_path, 'r') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            data = json.loads(line)\n",
    "            obj = Document(**data)\n",
    "            array.append(obj)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not matched chapter name and page_num, source: 车载12V电源......................................................... 128\n",
      "Not matched chapter name and page_num, source: 车载12V电源......................................................... 129\n",
      "Not matched chapter name and page_num, source: 4\n",
      "Not matched chapter name and page_num, source: 360°全景影像 .........................................................226\n",
      "Not matched chapter name and page_num, source: 6\n",
      "Not matched chapter name and page_num, source: 123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'前言': 9,\n",
       " '用车前准备': 15,\n",
       " '装载货物': 19,\n",
       " '上车和下车': 37,\n",
       " '驾驶前的准备': 49,\n",
       " '仪表和灯光': 67,\n",
       " '安全出行': 97,\n",
       " '启动和驾驶': 139,\n",
       " '驾驶辅助': 167,\n",
       " '空调': 239,\n",
       " '中央显示屏': 259,\n",
       " 'Lynk&CoApp': 279,\n",
       " '高压系统': 285,\n",
       " '保养和维护': 301,\n",
       " 'OTA升级': 323,\n",
       " '紧急情况下': 327,\n",
       " '技术资料': 345}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %timeit\n",
    "documents, table_of_content = parse_page_of_content()\n",
    "all_sub_sections = {sub_k : sub_v for _, v in table_of_content.items() for sub_k, sub_v in v.items() }\n",
    "\n",
    "\n",
    "all_key_word = list(all_sub_sections.keys()) \n",
    "\n",
    "\n",
    "section_key_word = list(table_of_content.keys())\n",
    "table_of_content, section_key_word\n",
    "\n",
    "# cut_section\n",
    "section_start_page_id = dict()\n",
    "for k, v in table_of_content.items():\n",
    "    section_start_page_id[k] = list(v.values())[0][0] - 2\n",
    "\n",
    "section_start_page_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_key_geq(d, x):\n",
    "    for key, value in reversed(d.items()):\n",
    "        if x >= value:\n",
    "            return key\n",
    "    return \"None\"  # 返回 None 如果没有找到满足条件的键\n",
    "\n",
    "with open(\"data/all_subsection_keys.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    all_sub_key_word = json.loads(f.read())\n",
    "\n",
    "\n",
    "documents = load_docs_from_jsonl('data/section_documents.jsonl')\n",
    "all_key_word = [doc.metadata[\"key_word\"] for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'page'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/lzw/project/LLM_IR/test.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blab246/home/lzw/project/LLM_IR/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m documents[\u001b[39m10\u001b[39;49m]\u001b[39m.\u001b[39;49mmetadata[\u001b[39m'\u001b[39;49m\u001b[39mpage\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, documents[\u001b[39m10\u001b[39m]\u001b[39m.\u001b[39mpage_content[:\u001b[39m10\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'page'"
     ]
    }
   ],
   "source": [
    "documents[10].metadata['page'] + 1, documents[10].page_content[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_docs_from_jsonl('data/page_documents.jsonl')\n",
    "page_id2doc = {doc.metadata[\"page\"]: doc for doc in documents}\n",
    "\n",
    "all_text = \"\"\n",
    "sub_section_key = \"\"\n",
    "\n",
    "for doc in documents:\n",
    "    # 页码删除 and 页眉删除\n",
    "    page_id = doc.metadata['page'] + 1\n",
    "    section_name = find_first_key_geq(section_start_page_id, page_id)\n",
    "    content = doc.page_content.replace(f\"{section_name}\\n{page_id}\", \"\")\n",
    "\n",
    "    new_lines = []\n",
    "    tmp = \"\"\n",
    "    ## 修正换行\n",
    "    for line in content.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        tmp += line\n",
    "        if line.endswith(\"。\"):\n",
    "            new_lines.append(tmp)\n",
    "            tmp = \"\"\n",
    "        elif line in all_key_word:\n",
    "            # 添加 <sub_section> 标签\n",
    "            sub_section_key = line\n",
    "            line = \"<\\sub_section>\\n\\n<sub_section>\" + line\n",
    "            new_lines.append(line)\n",
    "            tmp = \"\"\n",
    "        elif line in all_sub_key_word:\n",
    "            # TODO: 判断是否需要子章节\n",
    "            line = \"<SEP>\" + line\n",
    "            new_lines.append(line)\n",
    "            tmp = \"\"\n",
    "\n",
    "    new_lines.append(tmp)\n",
    "    content = \"\\n\".join(new_lines)\n",
    "\n",
    "    content = content.replace(\"警告！\", \"<SEP>警告:\\n\")\n",
    "    content = content.replace(\"注意！\", \"<SEP>注意:\\n\")\n",
    "    content = content.replace(\"说明！\", \"<SEP>说明:\\n\")\n",
    "    # all_text += f\"\\n<PAGE_SEP> page_id:{page_id}\\n\" + content\n",
    "    all_text += content\n",
    "\n",
    "# 去掉目录\n",
    "all_text = \"\\n\".join(all_text.split(\"\\n\")[12:])\n",
    "\n",
    "with open(\"data/all_text.txt\", \"w\") as f:\n",
    "    f.write(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def split_and_deduplicate(s):\n",
    "    # 按照\"。\"为分隔符切分字符串\n",
    "    parts = s.split(\"。\")\n",
    "    seen = set()\n",
    "    deduplicated_parts = []\n",
    "    # 去重，同时保证去重后的顺序不变\n",
    "    for part in parts:\n",
    "        if part not in seen:\n",
    "            seen.add(part)\n",
    "            deduplicated_parts.append(part)\n",
    "    return \"。\".join(deduplicated_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build section cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build section_documents & sub_section_documents\n",
    "def save_docs_to_jsonl(array:Iterable[Document], file_path:str)->None:\n",
    "    with open(file_path, 'w') as jsonl_file:\n",
    "        for doc in array:\n",
    "            jsonl_file.write(json.dumps(doc.dict(), ensure_ascii=False) + '\\n')\n",
    "\n",
    "\n",
    "sub_sections = all_text.split(\"<\\sub_section>\")\n",
    "\n",
    "# # section document cut\n",
    "# section_documents = []\n",
    "# sections_dict = defaultdict(str)\n",
    "\n",
    "# for sub_section in sub_sections:\n",
    "#     key_word = sub_section[2:].split(\"\\n\")[0].strip(\"<sub_section>\")\n",
    "#     sections_dict[key_word] += \"\\n\".join(sub_section[2:].split(\"\\n\")[1:])\n",
    "\n",
    "\n",
    "# for k, v in sections_dict.items():\n",
    "#     sections_dict[k] = split_and_deduplicate(v)\n",
    "#     section_documents.append(Document(page_content=sections_dict[k], metadata={\"key_word\":k}))\n",
    "\n",
    "# save_docs_to_jsonl(section_documents, \"data/section_documents.jsonl\")\n",
    "\n",
    "\n",
    "# sub_section cuts\n",
    "sub_section_documents = []\n",
    "sub_sections_dict = defaultdict(str)\n",
    "for sub_section in sub_sections:\n",
    "    sub_sub_sections = \"\\n\".join(sub_section.split(\"\\n\")[1:]).split(\"<SEP>\")\n",
    "    if len(sub_sub_sections) < 2:\n",
    "        continue\n",
    "\n",
    "    sub_sub_sections = [sec for sec in sub_sub_sections[1:] if not (sec.startswith(\"警告\") or sec.startswith(\"注意\") or sec.startswith(\"说明\") ) ]\n",
    "    for sub_sub_section in sub_sub_sections:\n",
    "        if len(sub_sub_section.split(\"\\n\")) < 2:\n",
    "            continue\n",
    "        sub_key_word = sub_sub_section.split(\"\\n\")[0]\n",
    "        sub_sections_dict[sub_key_word] += \"\\n\".join(sub_sub_section.split(\"\\n\")[1:])\n",
    "        # print(sub_key_word, sub_sections_dict[sub_key_word][:10])\n",
    "\n",
    "for k, v in sub_sections_dict.items():\n",
    "    sub_sections_dict[k] = split_and_deduplicate(v)\n",
    "    sub_section_documents.append(Document(page_content=sub_sections_dict[k], metadata={\"key_word\":k}))\n",
    "save_docs_to_jsonl(sub_section_documents, \"data/sub_section_documents.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_section_documents = load_docs_from_jsonl('data/sub_section_documents.jsonl')\n",
    "section_documents = load_docs_from_jsonl('data/section_documents.jsonl')\n",
    "\n",
    "\n",
    "# no overlap key\n",
    "section_key = [doc.metadata[\"key_word\"] for doc in section_documents]\n",
    "sub_section_key = [doc.metadata[\"key_word\"] for doc in sub_section_documents]\n",
    "\n",
    "set(section_key) & set(sub_section_key) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all\n",
    "def save_docs_to_jsonl(array:Iterable[Document], file_path:str)->None:\n",
    "    with open(file_path, 'w') as jsonl_file:\n",
    "        for doc in array:\n",
    "            jsonl_file.write(json.dumps(doc.dict(), ensure_ascii=False) + '\\n')\n",
    "\n",
    "\n",
    "all_documents = sub_section_documents + section_documents\n",
    "\n",
    "all_index = [Document(page_content=doc.metadata[\"key_word\"]) for doc in all_documents]\n",
    "all_index_db = FAISS.from_documents(all_index, embeddings)\n",
    "all_index_db.save_local(\"vector_store/all_index\")\n",
    "\n",
    "\n",
    "all_content = [Document(page_content=doc.page_content, metadata={\"key_word\":doc.metadata[\"key_word\"]}) for doc in all_documents]\n",
    "all_content_db = FAISS.from_documents(all_content, embeddings)\n",
    "all_content_db.save_local(\"vector_store/all_content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/lzw/.hf_models/stella-base-zh-v2. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/home/lzw/.hf_models/stella-base-zh-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\"device\": \"cuda\"} ,\n",
    "    encode_kwargs={\"normalize_embeddings\": False})\n",
    "\n",
    "sub_section_db = FAISS.from_documents(sub_section_documents, embeddings)\n",
    "sub_section_db.save_local(\"vector_store/sub_section_content\")\n",
    "\n",
    "# # db = FAISS.from_documents(key_index, embeddings)\n",
    "# sub_key_index = [Document(page_content=doc.metadata[\"key_word\"]) for doc in sub_section_documents]\n",
    "# sub_index_db = FAISS.from_documents(sub_key_index, embeddings)\n",
    "# sub_index_db.save_local(\"vector_store/sub_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search result: [(Document(page_content='通过遥控钥匙启动车辆'), -15.168591166312694), (Document(page_content='通过蓝牙钥匙启动车辆'), -59.629723803289494), (Document(page_content='使用遥控钥匙打开/关闭车窗'), -66.37679092038796), (Document(page_content='使用遥控钥匙解锁和闭锁'), -86.33092435450425)] 通过遥控钥匙启动车辆\n",
      "[(Document(page_content='通过遥控钥匙启动车辆'), -15.168591166312694), (Document(page_content='通过蓝牙钥匙启动车辆'), -59.629723803289494), (Document(page_content='使用遥控钥匙打开/关闭车窗'), -66.37679092038796), (Document(page_content='使用遥控钥匙解锁和闭锁'), -86.33092435450425)] \n",
      " [(Document(page_content='1请检查是否携带遥控钥匙。\\n<SEP>说明:\\n□只有经过正确编码的遥控钥匙才能启动车辆。\\n2请将挡位置于驻车挡（P）。\\n3将遥控钥匙放置于车内。\\n4将制动踏板踩到底。\\n5长按START/STOP按钮，车辆启动后松开按钮。\\n说明□动力电池电量充足时，纯电启动车辆，并点亮READY指示灯，此时发动机处于未启动状态。\\n车辆紧急启动遥控钥匙电池电量低，系统无法检测到钥匙时，仪表显示屏上会弹出消息提示您，未检测到钥匙。此时，请按照以下步骤启动车辆：1将遥控钥匙放入前杯托底部。\\n2按照前文中遥控钥匙启动车辆所述步骤启动车辆。\\n<SEP>注意:\\n■如果您尝试了三次都未能启动车辆，请避免再次尝试，并联系Lynk&Co领克中心。\\n<SEP>警告:\\n请严格遵循以下注意事项，有助于避免发生事故：■启动车辆前请检查确认方向盘、座椅、内后视镜或外后视镜是否调节到安全、舒适的位置。\\n■启动车辆前请检查制动踏板是否可以踩到底。\\n■请检查周围环境是否满足车辆启动的条件，若不满足切勿启动车辆。\\n■如果发动机还没有达到工作温度，请避免发动机的高转速和全油门，否则可能会损坏发动机。\\n■车辆行驶时，切勿将遥控钥匙带出车辆或使用START/STOP按钮，这样可能会导致发动机熄火。\\n', metadata={'key_word': '通过遥控钥匙启动车辆'}), -69.20644805876108)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzw/miniconda3/envs/Bert/lib/python3.8/site-packages/langchain/schema/vectorstore.py:275: UserWarning: Relevance scores must be between 0 and 1, got [(Document(page_content='1请检查是否携带遥控钥匙。\\n<SEP>说明:\\n□只有经过正确编码的遥控钥匙才能启动车辆。\\n2请将挡位置于驻车挡（P）。\\n3将遥控钥匙放置于车内。\\n4将制动踏板踩到底。\\n5长按START/STOP按钮，车辆启动后松开按钮。\\n说明□动力电池电量充足时，纯电启动车辆，并点亮READY指示灯，此时发动机处于未启动状态。\\n车辆紧急启动遥控钥匙电池电量低，系统无法检测到钥匙时，仪表显示屏上会弹出消息提示您，未检测到钥匙。此时，请按照以下步骤启动车辆：1将遥控钥匙放入前杯托底部。\\n2按照前文中遥控钥匙启动车辆所述步骤启动车辆。\\n<SEP>注意:\\n■如果您尝试了三次都未能启动车辆，请避免再次尝试，并联系Lynk&Co领克中心。\\n<SEP>警告:\\n请严格遵循以下注意事项，有助于避免发生事故：■启动车辆前请检查确认方向盘、座椅、内后视镜或外后视镜是否调节到安全、舒适的位置。\\n■启动车辆前请检查制动踏板是否可以踩到底。\\n■请检查周围环境是否满足车辆启动的条件，若不满足切勿启动车辆。\\n■如果发动机还没有达到工作温度，请避免发动机的高转速和全油门，否则可能会损坏发动机。\\n■车辆行驶时，切勿将遥控钥匙带出车辆或使用START/STOP按钮，这样可能会导致发动机熄火。\\n', metadata={'key_word': '通过遥控钥匙启动车辆'}), -69.20644805876108)]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "index_db = FAISS.load_local(\"vector_store/all_index\", embeddings)\n",
    "content_db = FAISS.load_local(\"vector_store/all_content\", embeddings)\n",
    "question = \"如何通过遥控钥匙启动车辆\"\n",
    "ret1 = index_db.similarity_search_with_relevance_scores(question)\n",
    "print(\"search result:\", ret1, ret1[0][0].page_content)\n",
    "related_str = content_db.similarity_search_with_relevance_scores(question, filter={\"key_word\": ret1[0][0].page_content})\n",
    "print(ret1, \"\\n\", related_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Sentence Cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_docs_from_jsonl('data/page_documents.jsonl')\n",
    "page_id2doc = {doc.metadata[\"page\"]: doc for doc in documents}\n",
    "\n",
    "all_text = \"\"\n",
    "sub_section_key = \"\"\n",
    "\n",
    "for doc in documents:\n",
    "    # 页码删除 and 页眉删除\n",
    "    page_id = doc.metadata['page'] + 1\n",
    "    section_name = find_first_key_geq(section_start_page_id, page_id)\n",
    "    content = doc.page_content.replace(f\"{section_name}\\n{page_id}\", \"\")\n",
    "\n",
    "    new_lines = []\n",
    "    tmp = \"\"\n",
    "    ## 修正换行\n",
    "    for line in content.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        tmp += line\n",
    "        if line.endswith(\"。\"):\n",
    "            new_lines.append(tmp)\n",
    "            tmp = \"\"\n",
    "        elif line in all_key_word:\n",
    "            # 添加 <sub_section> 标签\n",
    "            new_lines.append(line)\n",
    "            tmp = \"\"\n",
    "\n",
    "    new_lines.append(tmp)\n",
    "    content = \"\\n\".join(new_lines)\n",
    "\n",
    "    content = content.replace(\"警告！\", \"<SEP>警告:\\n\")\n",
    "    content = content.replace(\"注意！\", \"<SEP>注意:\\n\")\n",
    "    content = content.replace(\"说明！\", \"<SEP>说明:\\n\")\n",
    "    # all_text += f\"\\n<PAGE_SEP> page_id:{page_id}\\n\" + content\n",
    "    all_text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134198\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "print(\"all_text_len\", len(all_text))\n",
    "\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
