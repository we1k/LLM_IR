{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:10<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda:2'\n",
    "chatglm_path = \"chatglm3-6b/chatglm3-6b\"\n",
    "chatglm = AutoModel.from_pretrained(chatglm_path, trust_remote_code=True, device=device)\n",
    "chatglm = chatglm.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(data,prompt_template,chatglm,params,\n",
    "               loop = True) -> str:\n",
    "    \"\"\"\n",
    "    通过 ChatGLM 进行QA\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = {\n",
    "        \"question\": data[\"question\"],\n",
    "        \"info\":data[\"related_str\"]\n",
    "        }\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(chatglm_path, trust_remote_code=True)\n",
    "    # Execute the chain\n",
    "    response0, history = chatglm.chat(tokenizer,prompt_template[0].format(inputs[\"question\"],inputs[\"info\"]), history=[],**params)\n",
    "    # print(prompt_template[0].format(inputs[\"question\"],inputs[\"info\"][0] + inputs[\"info\"][1]))\n",
    "    if loop:\n",
    "        response, history = chatglm.chat(tokenizer,prompt_template[1].format(inputs[\"question\"]), history=history,**params)\n",
    "\n",
    "    return [response0,response]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result/related_str.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    json_data = file.read()\n",
    "datas = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "question: 100%|██████████| 100/100 [10:34<00:00,  6.35s/it]\n"
     ]
    }
   ],
   "source": [
    "prompt_template = [\"\"\"你是一位智能汽车使用说明的问答助手，现在需要根据已有信息，完整简要地回答问题，注意A在B内，B在C内，不要推断A在C内。问题是：{}\\n已有信息是：{}\"\"\",\n",
    "    \"\"\"请简要地总结先前的回答，只保留与问题最相关的部分，在总结中不要重复问题。问题是：{}\"\"\"]\n",
    "\n",
    "max_length = 4096\n",
    "top_p      = 0.6\n",
    "temperature= 0.5\n",
    "params = {\"max_length\":max_length,\"top_p\":top_p,\"temperature\":temperature}\n",
    "\n",
    "results = []\n",
    "for data in tqdm(datas,desc=\"question\"):\n",
    "    ret = get_answer(data,prompt_template,chatglm,params)\n",
    "    sample = {\"question\": data[\"question\"], \"answer_1\": ret[0], \"answer_2\": ret[1],\"answer_3\":\"\"}\n",
    "    results.append(sample)\n",
    "    # print(sample[\"answer_1\"])\n",
    "    # print(\"---\")\n",
    "    # print(sample[\"answer_2\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 读取JSON文件\n",
    "input_file = 'result/74.20.json'\n",
    "output_file = 'result/final10.json'\n",
    "\n",
    "with open(input_file, 'r', encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 保留question和answer字段\n",
    "filtered_data = []\n",
    "for item,result in zip(data,results):\n",
    "    filtered_item = {\n",
    "        \"question\": item.get(\"question\"),\n",
    "        \"answer_1\": result.get(\"answer_1\").replace(\"\\n\", \"\"),\n",
    "        \"answer_2\": result.get(\"answer_2\").replace(\"\\n\", \"\"),\n",
    "        \"answer_3\": item.get(\"answer_3\").replace(\"\\n\", \"\")\n",
    "    }\n",
    "    filtered_data.append(filtered_item)\n",
    "\n",
    "# 写入新的JSON文件\n",
    "with open(output_file, 'w', encoding=\"utf-8\") as file:\n",
    "    json.dump(filtered_data, file,ensure_ascii=False,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/final10.json', \"w\", encoding=\"utf-8\") as file :\n",
    "    json.dump(results, file,ensure_ascii=False,indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
